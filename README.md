# Neural network for deep learning
### Building a deep general purpose neural network from scratch
#### Features:
- 4 different activation functions: Sigmoid - Tanh - Relu - Linear
- Optional softmax activation for output layer
- Two different loss functions: Mean squared error - Cross entropy
- Two options for weight regularization: L1 - L2
- Any number of epochs - any mini batch size - any number of layers - any number of neurons in each layer
- Data generator for generating images to run classification on


## Demo

### Dataset
...
...

### Configuration
...
...

### Results
...
...
